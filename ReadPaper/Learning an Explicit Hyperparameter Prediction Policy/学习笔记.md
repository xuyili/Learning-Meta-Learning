# Learning an Explicit Hyperparameter Prediction Policy Conditioned on Tasks

### Abstract

首先定义了元学习器：

Specifically, this policy is represented as a parameterized function called meta-learner, mapping from a training/test task to its suitable hyperparameter setting, extracted from a pre-specified function set called meta learning machine

概述了本文使用了控制策略来改善元学习的泛化能力：

The theory naturally leads to some feasible controlling strategies for ameliorating the quality of the extracted meta-learner, verified to be able to finely ameliorate its generalization capability in some typical meta learning applications, including few-shot regression, few-shot classification and domain generalization.

### Introduction

1.阐述传统机器学习（包括深度学习）：

通常建模为参数化函数，预先指定函数集，近年来深度学习取得了巨大的成功。

2.存在的不足：

依赖于大量的标注数据。现实中只有很少很昂贵的数据，或有限的计算资源。

深度学习的结构复杂，具有大量超参数，容易过拟合。学习过程中每一个环节都涉及高度复杂的超参数配置。

如今，调参已经变得比学习本身还要复杂、耗时耗力。

3.解决超参数问题

AIC、BIC、MDL等方法。但局限于小尺寸的超参数结构。

面对复杂的结构，如深度学习，这样简单的方法通常没什么用。

最后还是要依赖专家的手动调参。

如果学习的目标任务是动态变化的，还得靠人对任务的理解来重新设计。

训练好以后，受限于种种问题，还不一定能推广到新的任务里，这时候超参数调整又得重新开始。

4.开始提出新的思路

使用显式超参数设置策略（explicit hyperparameter setting policy），自动调整参数。可以自适应不同任务的学习方法，不需要太多人工干预。

想要的是从学习任务空间（learning task space）到覆盖整个学习过程的超参数空间的映射。

5.开始介绍元学习

核心是 learning to learn。实现策略是学习一组指定的超参数，得到训练任务共享的超参数设置规则，推广到新的任务。

近年有许多元学习的研究，像AutoML（这个很出名，自动学习还在比赛中取得了很高的名次），算法选择 algorithm selection（这个听得不多），少样本学习few-shot learning（前面提过了，高频词），神经网络架构搜索neural architecture search（简称NAS，高频出现，强化学习的方法，适用于无法梯度下降的优化问题），超参数优化 hyperparameter optimization（这是个啥？）

6.元学习研究的两个主要问题

一、元学习任务都要共享固定的超参数，然后用来适应新的查询任务。这个本身就很难。

典型的有MAML（这个大名鼎鼎了），超参数优化，AutoML…

二、元学习理论大多数是在传统机器学习框架下发展的，侧重于评估传统模型的泛化能力。此外，很少有正则化的理论来指导元学习。

然后说了两个概念：

> from the conventional machine learning framework, this policy is modelled as a parameterized function, called meta-learner

> extracted from a pre-specified function set, called meta learning machine

然后论述了一通这个理论是可行的，废话太多我就不摘录了。

7.本文主要的贡献如下

一、把元学习理解为显性超参数预测的学习。

二、引入了一个 problem-agnostic的问题关于 meta-learner实现基于超参数预测的策略学习

三、将学习任务特定学习者的复杂性与学习任务可转移元学习者的复杂性分离开来

四、强调了元学习框架的作用

### Related Work

开始讲历史了……居然1937年就有了。

以前的文献都没有提出一个通用的元学习数学公式

2020年，有 Hospedales这一群人从3个独立的角度介绍了元学习分类：元表示、元优化器和元目标。

后面又有一群人，做的事都不痛不痒，在这就不说了。

2017年提出了基于梯度的MAML方法

在本文中，我们试图弥合元学习理论与实际应用之间的差距，并采用理论诱导的正则化策略来提高元学习的泛化能力。（其他都在灌水，不看了）

###  Exploring a Task-Transferable Meta-learner for Meta-learning

Task-Transferable：翻译成可转移任务？还是可迁移任务

$\mathcal{X}$ d维矩阵，输入空间

$\mathcal{Y}$  列向量，多分类的标签，输出空间。

$\mathcal{D} = \mathcal{X}* \mathcal{Y}$ 这个叫数据空间

$[k]=\{1,2,...,k\}$写作索引。

####  Learning a Learner from Learning Machine

啥标题啊，套娃呢？

一整段介绍了机器学习的概念，跳过。

如果我们将整个机器学习过程看作一个隐式函数，从一个输入训练数据集映射到一个决策模型，那么所有涉及的超参数就构成了这个函数的参数。

用函数表示：$LM(D;\theta):=D\rightarrow F$，$\psi$表示所有用到的超参数。用形如$\psi = (\psi_D,\psi_f,\psi_l,\psi_A)$的方式记录下来。

定理1，这里的符号有点绕，补充一下基本概念。

<img src="D:\MUST\Meta\Learning-Meta-Learning\ReadPaper\Learning an Explicit Hyperparameter Prediction Policy\学习笔记.assets\image-20220606144348844.png" alt="image-20220606144348844" style="zoom:67%;" />

**输入空间、特征空间和输出空间**

> 在监督学习中，将输入和输出所有可能的取值的集合分别称为**输入空间(input space)**和**输出空间(output space)**。
> 每个具体的输入是一个实例(instance)， 通常由特征向量(feature vector)表示。这时，所有特征向量存在的空间称为**特征空间(feature space)**。
> 在监督学习的过程中, 将输入和输出看作是定义在输入空间和输出空间上的随机变量的取值，习惯上**输入变量**和**输出变量**分别用大写字母 ![[公式]](https://www.zhihu.com/equation?tex=X) , ![[公式]](https://www.zhihu.com/equation?tex=Y) 表示。输入变量的取值用小写字母 ![[公式]](https://www.zhihu.com/equation?tex=x) 表示，输出变量的取值用小写字母 ![[公式]](https://www.zhihu.com/equation?tex=y) 表示

**期望风险**

> 损失函数的值越小， 模型就越好。由于模型的输入、输出 ![[公式]](https://www.zhihu.com/equation?tex=%28X%2CY%29) 是随机变量，遵循联合概率分布 ![[公式]](https://www.zhihu.com/equation?tex=P%28X%2CY%29) ，所以损失函数的期望（平均)表达为如下公式：
>
> ![[公式]](https://www.zhihu.com/equation?tex=R_%7Bexp%7D%28%5Ctheta%29%3DE_P%5BL%28y%2C+f%28x%2C%5Ctheta%29%29%5D+%3D+%5Cint_%7BX+%5Ctimes+Y%7DL%28y%2C+f%28x%2C+%5Ctheta%29%29P%28x%2Cy%29dxdy+%5Ctag%7B3-1%7D)

**经验风险**

>  将机器学习问题转换为一个优化问题的最简单的方法是通过**最小化训练集上的期望损失**。**这意味着用训练集上的经验分布** ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7BP%7D%28X%2CY%29) **,替代真实的分布** ![[公式]](https://www.zhihu.com/equation?tex=P%28X%2CY%29) 
>
>  将机器学习问题转换为一个优化问题的最简单的方法是通过*训练集上的平均损失
>
> ![[公式]](https://www.zhihu.com/equation?tex=R%7Bemp%7D%28%5Ctheta%29+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bn%3D1%7D%5E%7BN%7DL%28y%2C+f%28x%2C%5Ctheta%29%29+%5Ctag%7B4-1%7D)

 这种基于最小化平均训练误差的训练过程被称为**经验风险最小化（empirical risk minimization）**。**这种情况下我们并不是直接最优化风险，而是最优化经验风险。**

#### Learning a Meta-learner from Meta-learning Machine

我们的目标是探索一种显式的超参数预测策略，用于在适应新的查询任务时预测适当的超参数设置。
