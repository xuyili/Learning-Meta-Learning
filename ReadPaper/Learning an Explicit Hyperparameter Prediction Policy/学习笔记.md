# Learning an Explicit Hyperparameter Prediction Policy Conditioned on Tasks

### Abstract

首先定义了元学习器：

Specifically, this policy is represented as a parameterized function called meta-learner, mapping from a training/test task to its suitable hyperparameter setting, extracted from a pre-specified function set called meta learning machine

概述了本文使用了控制策略来改善元学习的泛化能力：

The theory naturally leads to some feasible controlling strategies for ameliorating the quality of the extracted meta-learner, verified to be able to finely ameliorate its generalization capability in some typical meta learning applications, including few-shot regression, few-shot classification and domain generalization.

### Introduction

1.阐述传统机器学习（包括深度学习）：

通常建模为参数化函数，预先指定函数集，近年来深度学习取得了巨大的成功。

2.存在的不足：

依赖于大量的标注数据。现实中只有很少很昂贵的数据，或有限的计算资源。

深度学习的结构复杂，具有大量超参数，容易过拟合。学习过程中每一个环节都涉及高度复杂的超参数配置。

如今，调参已经变得比学习本身还要复杂、耗时耗力。

3.解决超参数问题

AIC、BIC、MDL等方法。但局限于小尺寸的超参数结构。

面对复杂的结构，如深度学习，这样简单的方法通常没什么用。

最后还是要依赖专家的手动调参。

如果学习的目标任务是动态变化的，还得靠人对任务的理解来重新设计。

训练好以后，受限于种种问题，还不一定能推广到新的任务里，这时候超参数调整又得重新开始。

4.开始提出新的思路

使用显式超参数设置策略（explicit hyperparameter setting policy），自动调整参数。可以自适应不同任务的学习方法，不需要太多人工干预。

想要的是从学习任务空间（learning task space）到覆盖整个学习过程的超参数空间的映射。

5.开始介绍元学习

核心是 learning to learn。实现策略是学习一组指定的超参数，得到训练任务共享的超参数设置规则，推广到新的任务。

近年有许多元学习的研究，像AutoML（这个很出名，自动学习还在比赛中取得了很高的名次），算法选择 algorithm selection（这个听得不多），少样本学习few-shot learning（前面提过了，高频词），神经网络架构搜索neural architecture search（简称NAS，高频出现，强化学习的方法，适用于无法梯度下降的优化问题），超参数优化 hyperparameter optimization（这是个啥？）

6.元学习研究的两个主要问题

一、元学习任务都要共享固定的超参数，然后用来适应新的查询任务。这个本身就很难。

典型的有MAML（这个大名鼎鼎了），超参数优化，AutoML…

二、元学习理论大多数是在传统机器学习框架下发展的，侧重于评估传统模型的泛化能力。此外，很少有正则化的理论来指导元学习。

然后说了两个概念：

> from the conventional machine learning framework, this policy is modelled as a parameterized function, called meta-learner

> extracted from a pre-specified function set, called meta learning machine

然后论述了一通这个理论是可行的，废话太多我就不摘录了。

7.本文主要的贡献如下

一、把元学习理解为显性超参数预测的学习。

二、引入了一个 problem-agnostic的问题关于 meta-learner实现基于超参数预测的策略学习

三、将学习任务特定学习者的复杂性与学习任务可转移元学习者的复杂性分离开来

四、强调了元学习框架的作用

### Related Work

开始讲历史了……居然1937年就有了。

以前的文献都没有提出一个通用的元学习数学公式

2020年，有 Hospedales这一群人从3个独立的角度介绍了元学习分类：元表示、元优化器和元目标。

后面又有一群人，做的事都不痛不痒，在这就不说了。

2017年提出了基于梯度的MAML方法

在本文中，我们试图弥合元学习理论与实际应用之间的差距，并采用理论诱导的正则化策略来提高元学习的泛化能力。（其他都在灌水，不看了）

###  Exploring a Task-Transferable Meta-learner for Meta-learning

Task-Transferable：翻译成可转移任务？还是可迁移任务

$\mathcal{X}$ d维矩阵，输入空间

$\mathcal{Y}$  列向量，多分类的标签，输出空间。

$\mathcal{D} = \mathcal{X}* \mathcal{Y}$ 这个叫数据空间

$[k]=\{1,2,...,k\}$写作索引。

####  Learning a Learner from Learning Machine

啥标题啊，套娃呢？

一整段介绍了机器学习的概念，跳过。

如果我们将整个机器学习过程看作一个隐式函数，从一个输入训练数据集映射到一个决策模型，那么所有涉及的超参数就构成了这个函数的参数。

用函数表示：$LM(D;\theta):=D\rightarrow F$，$\psi$表示所有用到的超参数。用形如$\psi = (\psi_D,\psi_f,\psi_l,\psi_A)$的方式记录下来。

定理1，这里的符号有点绕，补充一下基本概念。

<img src="D:\MUST\Meta\Learning-Meta-Learning\ReadPaper\Learning an Explicit Hyperparameter Prediction Policy\学习笔记.assets\image-20220606144348844.png" alt="image-20220606144348844" style="zoom:67%;" />

**输入空间、特征空间和输出空间**

> 在监督学习中，将输入和输出所有可能的取值的集合分别称为**输入空间(input space)**和**输出空间(output space)**。
> 每个具体的输入是一个实例(instance)， 通常由特征向量(feature vector)表示。这时，所有特征向量存在的空间称为**特征空间(feature space)**。
> 在监督学习的过程中, 将输入和输出看作是定义在输入空间和输出空间上的随机变量的取值，习惯上**输入变量**和**输出变量**分别用大写字母 ![[公式]](https://www.zhihu.com/equation?tex=X) , ![[公式]](https://www.zhihu.com/equation?tex=Y) 表示。输入变量的取值用小写字母 ![[公式]](https://www.zhihu.com/equation?tex=x) 表示，输出变量的取值用小写字母 ![[公式]](https://www.zhihu.com/equation?tex=y) 表示

**期望风险**

> 损失函数的值越小， 模型就越好。由于模型的输入、输出 ![[公式]](https://www.zhihu.com/equation?tex=%28X%2CY%29) 是随机变量，遵循联合概率分布 ![[公式]](https://www.zhihu.com/equation?tex=P%28X%2CY%29) ，所以损失函数的期望（平均)表达为如下公式：
>
> ![[公式]](https://www.zhihu.com/equation?tex=R_%7Bexp%7D%28%5Ctheta%29%3DE_P%5BL%28y%2C+f%28x%2C%5Ctheta%29%29%5D+%3D+%5Cint_%7BX+%5Ctimes+Y%7DL%28y%2C+f%28x%2C+%5Ctheta%29%29P%28x%2Cy%29dxdy+%5Ctag%7B3-1%7D)

**经验风险**

>  将机器学习问题转换为一个优化问题的最简单的方法是通过**最小化训练集上的期望损失**。**这意味着用训练集上的经验分布** ![[公式]](https://www.zhihu.com/equation?tex=%5Chat%7BP%7D%28X%2CY%29) **,替代真实的分布** ![[公式]](https://www.zhihu.com/equation?tex=P%28X%2CY%29) 
>
>  将机器学习问题转换为一个优化问题的最简单的方法是通过*训练集上的平均损失
>
> ![[公式]](https://www.zhihu.com/equation?tex=R%7Bemp%7D%28%5Ctheta%29+%3D+%5Cfrac%7B1%7D%7BN%7D%5Csum_%7Bn%3D1%7D%5E%7BN%7DL%28y%2C+f%28x%2C%5Ctheta%29%29+%5Ctag%7B4-1%7D)

 这种基于最小化平均训练误差的训练过程被称为**经验风险最小化（empirical risk minimization）**。**这种情况下我们并不是直接最优化风险，而是最优化经验风险。**

#### Learning a Meta-learner from Meta-learning Machine

我们的目标是探索一种显式的超参数预测策略，用于在适应新的查询任务时预测适当的超参数设置。

本文的研究重点主要在数学公式和学习理论上。只考虑静态任务。

我们的目标是学习一种适用于一系列任务的通用超参数预测策略。

优化变量现在是元学习器的参数，而不是要估计的超参数。

#### Comparison with Multi-task/Transfer Learning

简短地阐明上述元学习框架与传统的多任务/迁移学习方法的主要区别。

迁移学习也利用了多任务之间的内在关系来提高学习结果的泛化性能，但仍属于传统机器学习的范畴。大多数传统的多任务/迁移学习研究的目的是通过利用潜在的相关性来改善多个学习器对不同任务施加的参数，从而提高任务学习性能。

而元学习则是从任务/元学习者的层面考虑这个问题，旨在学习单一元学习者在不同任务下的参数设定策略。这种学习方式比传统的学习方式更倾向于在实践中更好地提高其灵活性、可用范围和潜在能力。从学习方法论的角度考虑，这种学习方式比以前的许多机器学习方式具有更广泛的应用潜力。

### Learning Theory

用两个阶段来描述上述元学习框架的学习范式。

第一个阶段是元训练阶段，目的是学习超参数预测策略。

第二个阶段是元测试阶段，目的是推广该策略，为新的查询任务设置学习方法。

#### Preliminaries

我们用高斯复杂度来度量函数类的复杂度。

vector-valued function:向量值函数，有时也称为向量函数，是一个单变量或多变量的、值域是多维向量或者无穷维向量的集合的函数。向量值函数的输入可以是一个标量或者一个向量（定义域的维度可以是1或大于1）；定义域的维度不取决于值域的维度。

#### Meta-Training Stage: Learning the Hyperparameter Prediction Policy

平均风险边界由三个主要部分组成。

元学习器h的复杂性，任务学习器f的复杂性，支持集和查询集的分布变化

经过一堆乱七八糟的证明，说明了即使训练任务数量不足，提高任务中查询样本的数量也有助于提取的元学习器的最终性能。

在当前的许多元学习应用中，可以在不是很大的训练任务集(即使只有一个训练任务)的基础上获得良好的性能，例如超参数学习(Franceschi et al.， 2018)，神经结构搜索(NAS) (Elsken et al.， 2019)等。

因此，我们的结果可以为这些方法提供更合理、更全面的理论解释。

最近的理论研究并探索了基于梯度的元学习的收敛保证。但是，他们研究的是损失函数是凸的或者映射是线性的情况，这在深度神经网络上分析可能比较困难。此外，研究的训练策略不是情景的，这往往不容易用于训练实际流行的元算法。

与前面提到的工作不同，我们开发了理论结果，然后是支持/查询训练策略。此外，理论保证包含元学习器h和元学习器f的复杂性，容易诱导元学习器的控制效果，提高元算法的泛化能力。

#### Meta-Test Stage: Generalizing to New Query Tasks

